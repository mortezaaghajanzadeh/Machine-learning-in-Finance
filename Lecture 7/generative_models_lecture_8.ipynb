{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mortezaaghajanzadeh/Machine-learning-in-Finance/blob/main/Lecture%206/generative_models_lecture_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 8: Generative Models.**\n",
        "### Based on code from Chapter 9 in ``Machine Learning for Economics and Finance in TensorFlow 2'' (Hull, 2021)."
      ],
      "metadata": {
        "id": "uTxaRXhp98WS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries.\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "RH3GPpmU-KAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 9-1.** Prepare GDP growth data for use in a VAE."
      ],
      "metadata": {
        "id": "w5Lycwa7-SE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and transpose data.\n",
        "GDP = pd.read_csv(data_path+'https://www.dropbox.com/scl/fi/aw870w901t7w4ggtmr4a6/gdp_growth.csv?rlkey=4piz3yzhx10d8bn3nxaionasc&dl=1',\n",
        "\tindex_col = 'Date').T\n",
        "\n",
        "# Print data preview.\n",
        "print(GDP.head())\n",
        "\n",
        "# Convert data to numpy array.\n",
        "GDP = np.array(GDP)\n",
        "\n",
        "# Set number of countries and quarters.\n",
        "nCountries, nQuarters = GDP.shape\n",
        "\n",
        "# Set number of latent nodes and batch size.\n",
        "latentNodes = 2\n",
        "batchSize = 1"
      ],
      "metadata": {
        "id": "UG5DW7dd5kxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 9-2.** Define function to perform sampling task in VAE."
      ],
      "metadata": {
        "id": "WQojvs3s-daM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function for sampling layer.\n",
        "def sampling(params, batchSize = batchSize, latentNodes = latentNodes):\n",
        "\tmean, lvar = params\n",
        "\tepsilon = tf.random.normal(shape=(\n",
        "\tbatchSize, latentNodes))\n",
        "\treturn mean + tf.exp(lvar / 2.0) * epsilon"
      ],
      "metadata": {
        "id": "j5E5gGui9UGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 9-3.** Define encoder model for VAE."
      ],
      "metadata": {
        "id": "gKYwm-I1-70A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layer for encoder.\n",
        "encoderInput = tf.keras.layers.Input(shape = (nQuarters))\n",
        "\n",
        "# Define latent state.\n",
        "latent = tf.keras.layers.Input(shape = (latentNodes))\n",
        "\n",
        "# Define mean layer.\n",
        "mean = tf.keras.layers.Dense(latentNodes)(encoderInput)\n",
        "\n",
        "# Define log variance layer.\n",
        "lvar = tf.keras.layers.Dense(latentNodes)(encoderInput)\n",
        "\n",
        "# Define sampling layer.\n",
        "encoded = tf.keras.layers.Lambda(sampling, output_shape=(latentNodes,))([mean, lvar])\n",
        "\n",
        "# Define model for encoder.\n",
        "encoder = tf.keras.Model(encoderInput, [mean, lvar, encoded])"
      ],
      "metadata": {
        "id": "eZmvxTpF9WZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 9-4.** Define decoder model for VAE."
      ],
      "metadata": {
        "id": "1hOJKAxZGITB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define output for decoder.\n",
        "decoded = tf.keras.layers.Dense(nQuarters, activation = 'linear')(latent)\n",
        "\n",
        "# Define the decoder model.\n",
        "decoder = tf.keras.Model(latent, decoded)\n",
        "\n",
        "# Define functional model for autoencoder.\n",
        "vae = tf.keras.Model(encoderInput, decoder(encoded))"
      ],
      "metadata": {
        "id": "9YN2Cwi19ZYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 9-5.** Define VAE loss."
      ],
      "metadata": {
        "id": "vvq4U6R6GOQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the reconstruction component of the loss.\n",
        "reconstruction = tf.keras.losses.binary_crossentropy(\n",
        "vae.inputs[0], vae.outputs[0])\n",
        "\n",
        "# Compute the KL loss component.\n",
        "kl = -0.5 * tf.reduce_mean(1 + lvar - tf.square(mean) - tf.exp(lvar), axis = -1)\n",
        "\n",
        "# Combine the losses and add them to the model.\n",
        "combinedLoss = reconstruction + kl\n",
        "vae.add_loss(combinedLoss)"
      ],
      "metadata": {
        "id": "YRtVQHiY9ay4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 9-6.** Compile and fit VAE."
      ],
      "metadata": {
        "id": "ckX9jaWpGW21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model.\n",
        "vae.compile(optimizer='adam')\n",
        "\n",
        "# Fit model.\n",
        "vae.fit(GDP, batch_size = batchSize, epochs = 100)"
      ],
      "metadata": {
        "id": "hE_5fjwh9cTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 9-7.** Generate latent states and time series with trained VAE."
      ],
      "metadata": {
        "id": "RAFRa4pJgcve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate series reconstruction.\n",
        "prediction = vae.predict(GDP[0,:].reshape(1,236))\n",
        "\n",
        "# Generate (random) latent state from inputs.\n",
        "latentState = encoder.predict(GDP[0,:].reshape(1,236))\n",
        "\n",
        "# Perturb latent state.\n",
        "latentState[0] = latentState[0] + np.random.normal(1)\n",
        "\n",
        "# Pass perturbed latent state to decoder.\n",
        "decoder.predict(latentState)"
      ],
      "metadata": {
        "id": "YR7Ay7A5gfRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 9-8.** Prepare GDP growth data for use in a GAN."
      ],
      "metadata": {
        "id": "iApx9mwbgklu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and transpose data.\n",
        "GDP = pd.read_csv(data_path+'https://www.dropbox.com/scl/fi/aw870w901t7w4ggtmr4a6/gdp_growth.csv?rlkey=4piz3yzhx10d8bn3nxaionasc&dl=1',\n",
        "        index_col = 'Date').T\n",
        "\n",
        "# Convert pandas DataFrame to numpy array.\n",
        "GDP = np.array(GDP)"
      ],
      "metadata": {
        "id": "yMgNku-Zgo--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 9-9.** Define the generative model of a GAN."
      ],
      "metadata": {
        "id": "Ea_mSHWhgqq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set dimension of latent state vector.\n",
        "nLatent = 2\n",
        "\n",
        "# Set number of countries and quarters.\n",
        "nCountries, nQuarters = GDP.shape\n",
        "\n",
        "# Define input layer.\n",
        "generatorInput = tf.keras.layers.Input(shape = (nLatent,))\n",
        "\n",
        "# Define hidden layer.\n",
        "generatorHidden = tf.keras.layers.Dense(16, activation='relu')(generatorInput)\n",
        "\n",
        "# Define generator output layer.\n",
        "generatorOutput = tf.keras.layers.Dense(236, activation='linear')(generatorHidden)\n",
        "\n",
        "# Define generator model.\n",
        "generator = tf.keras.Model(inputs = generatorInput, outputs = generatorOutput)"
      ],
      "metadata": {
        "id": "thtIaWrOgxd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 9-10.** Define and compile the discriminator model of a GAN."
      ],
      "metadata": {
        "id": "2GIrEebzgzaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layer.\n",
        "discriminatorInput = tf.keras.layers.Input(shape = (nQuarters,))\n",
        "\n",
        "# Define hidden layer.\n",
        "discriminatorHidden = tf.keras.layers.Dense(16, activation='relu')(discriminatorInput)\n",
        "\n",
        "# Define discriminator output layer.\n",
        "discriminatorOutput = tf.keras.layers.Dense(1, activation='sigmoid')(discriminatorHidden)\n",
        "\n",
        "# Define discriminator model.\n",
        "discriminator = tf.keras.Model(inputs = discriminatorInput, outputs = discriminatorOutput)\n",
        "\n",
        "# Compile discriminator.\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=tf.optimizers.Adam(0.0001))"
      ],
      "metadata": {
        "id": "Hjsbt6jGtLW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 9-11.** Define and compile the adversarial model of a GAN."
      ],
      "metadata": {
        "id": "yDM34wVeg4HM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layer for adversarial network.\n",
        "adversarialInput = tf.keras.layers.Input(shape=(nLatent))\n",
        "\n",
        "# Define generator output as generated time series.\n",
        "timeSeries = generator(adversarialInput)\n",
        "\n",
        "# Set discriminator to be untrainable.\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Compute predictions from discriminator.\n",
        "adversarialOutput = discriminator(timeSeries)\n",
        "\n",
        "# Define adversarial model.\n",
        "adversarial = tf.keras.Model(adversarialInput, adversarialOutput)\n",
        "\n",
        "# Compile adversarial network.\n",
        "adversarial.compile(loss='binary_crossentropy', optimizer=tf.optimizers.Adam(0.0001))"
      ],
      "metadata": {
        "id": "L9-xsXDVg-st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 9-12.** Train the discriminator and the adversarial network."
      ],
      "metadata": {
        "id": "jUl34j9QGlrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set batch size.\n",
        "batch, halfBatch = 12, 6\n",
        "\n",
        "for j in range(1000):\n",
        "\t# Draw real training data.\n",
        "\tidx = np.random.randint(nCountries, size = halfBatch)\n",
        "\treal_gdp_series = GDP[idx, :]\n",
        "\n",
        "\t# Generate fake training data.\n",
        "\tlatentState = np.random.normal(size=[halfBatch, nLatent])\n",
        "\tfake_gdp_series = generator.predict(latentState)\n",
        "\n",
        "\t# Combine input data.\n",
        "\tfeatures = np.concatenate((real_gdp_series, fake_gdp_series))\n",
        "\n",
        "\t# Create labels.\n",
        "\tlabels = np.ones([batch,1])\n",
        "\tlabels[halfBatch:, :] = 0\n",
        "\n",
        "\t# Train discriminator.\n",
        "\tdiscriminator.train_on_batch(features, labels)\n",
        "\n",
        "\t# Generate latent state for adversarial net.\n",
        "\tlatentState = np.random.normal(size=[batch, nLatent])\n",
        "\n",
        "\t# Generate labels for adversarial network.\n",
        "\tlabels = np.ones([batch, 1])\n",
        "\n",
        "\t# Train adversarial network.\n",
        "\tadversarial.train_on_batch(latentState, labels)"
      ],
      "metadata": {
        "id": "UnDdrdqFGnE_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}