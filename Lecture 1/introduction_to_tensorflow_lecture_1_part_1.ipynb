{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mortezaaghajanzadeh/Machine-learning-in-Finance/blob/main/Lecture%201/introduction_to_tensorflow_lecture_1_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTxaRXhp98WS"
      },
      "source": [
        "# **Lecture 1 (Part 1): Introduction to TensorFlow in Python.**\n",
        "### Based on code from Chapter 1 in ``Machine Learning for Economics and Finance in TensorFlow 2'' (Hull, 2021)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RH3GPpmU-KAp"
      },
      "outputs": [],
      "source": [
        "# Import libraries.\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5Lycwa7-SE6"
      },
      "source": [
        "## **Listing 1-2.** Implement OLS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9dAZ-Dx9QD4",
        "outputId": "ccb25630-5115-4a03-c680-30d2ff35a143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.14.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
              "array([[2.],\n",
              "       [1.]], dtype=float32)>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(tf.__version__)\n",
        "\n",
        "# Define the data as constants.\n",
        "X = tf.constant([[1, 0], [1, 2]], tf.float32)\n",
        "Y = tf.constant([[2], [4]], tf.float32)\n",
        "\n",
        "# Matrix multiply X by X’s transpose and invert.\n",
        "beta_0 = tf.linalg.inv(tf.matmul(tf.transpose(X), X))\n",
        "\n",
        "# Matrix multiply beta_0 by X’s transpose.\n",
        "beta_1 = tf.matmul(beta_0, tf.transpose(X))\n",
        "\n",
        "# Matrix multiply beta_1 by Y.\n",
        "beta = tf.matmul(beta_1, Y)\n",
        "beta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQojvs3s-daM"
      },
      "source": [
        "## **Listing 1-4.** Print tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5E5gGui9UGy",
        "outputId": "c6b0c455-d783-4ca9-a048-d73d54716475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1. 0.]\n",
            " [1. 2.]], shape=(2, 2), dtype=float32)\n",
            "[[2.]\n",
            " [1.]]\n"
          ]
        }
      ],
      "source": [
        "# Print the feature matrix.\n",
        "print(X)\n",
        "\n",
        "# Print the coefficient vector.\n",
        "print(beta.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKYwm-I1-70A"
      },
      "source": [
        "## **Listing 1-6.** Generate OLS predictions with static graphs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZmvxTpF9WZv",
        "outputId": "470587b2-518d-49c9-c67d-130908a060a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[2.]\n",
            " [4.]], shape=(2, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Define OLS prediction function as static graph.\n",
        "@tf.function\n",
        "def ols_predict(X, beta):\n",
        "\ty_hat = tf.matmul(X, beta)\n",
        "\treturn y_hat\n",
        "\n",
        "# Predict Y using X and beta.\n",
        "predictions = ols_predict(X, beta)\n",
        "\n",
        "# Print predictions.\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hOJKAxZGITB"
      },
      "source": [
        "## **Listing 1-7.** Solve an OLS model with tf.keras()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YN2Cwi19ZYI",
        "outputId": "0698e199-a93f-4e29-9e65-4389c0d24a24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 7.8817\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.0779\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3562\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7080\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1259\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6032\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1338\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7123\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3337\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9938\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6885\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 2.4144\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1682\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9471\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 991us/step - loss: 1.7486\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5703\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4102\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2664\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1373\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0213\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.9172\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.8237\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7397\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6643\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5966\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.5358\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4811\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.4321\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3881\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3485\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3130\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2811\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 992us/step - loss: 0.2524\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2267\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 0.2036\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1829\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 993us/step - loss: 0.1642\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1475\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1325\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 0.1190\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1069\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0960\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0862\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0774\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 995us/step - loss: 0.0696\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0625\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0561\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0504\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0453\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0407\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0366\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0328\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 993us/step - loss: 0.0295\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0265\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0238\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0214\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0192\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0173\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 0.0155\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0140\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0126\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0113\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0102\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0091\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0082\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 993us/step - loss: 0.0074\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0066\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0060\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0054\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0048\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0044\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0039\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0035\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0032\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0029\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0026\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0023\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 0.0017\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0016\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 0.0010\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.4762e-04\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.6005e-04\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.8127e-04\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 993us/step - loss: 7.1039e-04\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4660e-04\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 5.8918e-04\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3748e-04\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9094e-04\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4901e-04\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 996us/step - loss: 4.1124e-04\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7720e-04\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4650e-04\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 993us/step - loss: 3.1883e-04\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9384e-04\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7131e-04\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 996us/step - loss: 2.5095e-04\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3256e-04\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1592e-04\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0089e-04\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8728e-04\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 996us/step - loss: 1.7495e-04\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6378e-04\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5365e-04\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4444e-04\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3608e-04\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 1.2847e-04\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2155e-04\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1524e-04\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0947e-04\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0421e-04\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.9387e-05\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 9.4975e-05\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0920e-05\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.7197e-05\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.3768e-05\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.0604e-05\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7684e-05\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.4979e-05\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.2471e-05\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.0141e-05\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 992us/step - loss: 6.7971e-05\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.5947e-05\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4054e-05\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2281e-05\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 993us/step - loss: 6.0617e-05\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9050e-05\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7573e-05\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 998us/step - loss: 5.6178e-05\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4857e-05\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3603e-05\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2410e-05\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1277e-05\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0193e-05\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 993us/step - loss: 4.9157e-05\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8165e-05\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7213e-05\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6298e-05\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5416e-05\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4565e-05\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 996us/step - loss: 4.3745e-05\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2951e-05\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2183e-05\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1437e-05\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 4.0715e-05\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0013e-05\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9328e-05\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8663e-05\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8014e-05\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7381e-05\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6764e-05\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6161e-05\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5570e-05\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4994e-05\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.4430e-05\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 3.3877e-05\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3336e-05\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2806e-05\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 992us/step - loss: 3.2286e-05\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1776e-05\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1275e-05\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0785e-05\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0303e-05\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9829e-05\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9364e-05\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8908e-05\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8459e-05\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.8018e-05\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7585e-05\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7159e-05\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6740e-05\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6327e-05\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 996us/step - loss: 2.5922e-05\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5523e-05\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5131e-05\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 995us/step - loss: 2.4745e-05\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4366e-05\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3992e-05\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 2.3624e-05\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3263e-05\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2906e-05\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2556e-05\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2211e-05\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1871e-05\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1536e-05\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.1208e-05\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0885e-05\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.0566e-05\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0252e-05\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9943e-05\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9639e-05\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9339e-05\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 993us/step - loss: 1.9044e-05\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8754e-05\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8468e-05\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8186e-05\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7909e-05\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 994us/step - loss: 1.7636e-05\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7367e-05\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7103e-05\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6842e-05\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6585e-05\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6333e-05\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6084e-05\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5839e-05\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5597e-05\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.5359e-05\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5126e-05\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4896e-05\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4669e-05\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 996us/step - loss: 1.4446e-05\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4225e-05\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4009e-05\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3796e-05\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 1.3586e-05\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3379e-05\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3175e-05\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2974e-05\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2777e-05\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2583e-05\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.2391e-05\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2203e-05\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2017e-05\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1834e-05\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 993us/step - loss: 1.1654e-05\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1476e-05\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1302e-05\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1130e-05\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 995us/step - loss: 1.0961e-05\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0794e-05\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0630e-05\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0468e-05\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0309e-05\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0152e-05\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.9975e-06\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.8453e-06\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 9.6955e-06\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.5476e-06\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.4021e-06\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.2590e-06\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.1177e-06\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9788e-06\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.8418e-06\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 8.7071e-06\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.5745e-06\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.4437e-06\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.3152e-06\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.1886e-06\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.0639e-06\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.9410e-06\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.8203e-06\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7014e-06\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.5843e-06\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.4689e-06\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.3554e-06\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.2436e-06\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.1331e-06\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0243e-06\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.9172e-06\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8118e-06\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.7080e-06\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.6059e-06\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.5056e-06\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4069e-06\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3090e-06\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2126e-06\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.1180e-06\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.0249e-06\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9333e-06\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8432e-06\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7542e-06\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.6662e-06\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5801e-06\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4951e-06\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4118e-06\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.3296e-06\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2483e-06\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1684e-06\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0899e-06\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 5.0127e-06\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9364e-06\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8612e-06\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7872e-06\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7146e-06\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 996us/step - loss: 4.6426e-06\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5720e-06\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5027e-06\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4339e-06\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 4.3663e-06\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2999e-06\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2347e-06\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1700e-06\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1065e-06\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0442e-06\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9824e-06\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9220e-06\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8623e-06\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8033e-06\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7455e-06\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6887e-06\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6324e-06\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5771e-06\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5229e-06\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4691e-06\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4163e-06\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3642e-06\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 998us/step - loss: 3.3128e-06\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2625e-06\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2126e-06\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1638e-06\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1157e-06\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 3.0683e-06\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0217e-06\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9756e-06\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9303e-06\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8860e-06\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8420e-06\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.7988e-06\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7562e-06\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7144e-06\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 2.6728e-06\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6323e-06\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5920e-06\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5525e-06\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5138e-06\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 996us/step - loss: 2.4755e-06\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4380e-06\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4009e-06\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3644e-06\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3283e-06\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2930e-06\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2581e-06\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2238e-06\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 2.1898e-06\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1565e-06\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 2.1237e-06\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 998us/step - loss: 2.0915e-06\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0595e-06\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0283e-06\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9974e-06\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9671e-06\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9371e-06\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9077e-06\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8787e-06\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.8502e-06\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8221e-06\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 1.7943e-06\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7670e-06\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7400e-06\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7136e-06\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 1.6873e-06\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6617e-06\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 1.6364e-06\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6117e-06\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5871e-06\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5629e-06\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 1.5391e-06\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5156e-06\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4927e-06\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4699e-06\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4477e-06\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.4257e-06\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4039e-06\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3826e-06\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3615e-06\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.3409e-06\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3205e-06\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3004e-06\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2807e-06\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2613e-06\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2419e-06\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 996us/step - loss: 1.2230e-06\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2042e-06\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1860e-06\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1680e-06\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1501e-06\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1326e-06\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1155e-06\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0983e-06\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 1.0817e-06\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0653e-06\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0489e-06\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 1.0329e-06\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0172e-06\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0017e-06\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.8658e-07\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.7152e-07\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.5683e-07\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 9.4225e-07\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.2786e-07\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.1389e-07\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.0002e-07\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 8.8627e-07\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 996us/step - loss: 8.7269e-07\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.5945e-07\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 8.4638e-07\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.3334e-07\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.2070e-07\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.0822e-07\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.9584e-07\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.8378e-07\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7194e-07\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.6007e-07\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.4863e-07\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 7.3728e-07\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 7.2602e-07\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.1484e-07\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.0409e-07\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.9330e-07\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8271e-07\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.7241e-07\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.6219e-07\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 6.5211e-07\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 6.4211e-07\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3245e-07\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2280e-07\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.1328e-07\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.0390e-07\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 5.9472e-07\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 5.8567e-07\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7675e-07\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 5.6803e-07\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5944e-07\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 5.5091e-07\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4250e-07\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3434e-07\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2624e-07\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.1821e-07\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.1029e-07\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0243e-07\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.9481e-07\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.8730e-07\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 4.7985e-07\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7245e-07\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6534e-07\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 4.5823e-07\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 4.5128e-07\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4433e-07\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3765e-07\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.3097e-07\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2444e-07\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1791e-07\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 996us/step - loss: 4.1148e-07\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 998us/step - loss: 4.0527e-07\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9914e-07\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9302e-07\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8699e-07\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8117e-07\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 3.7543e-07\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6969e-07\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6404e-07\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5844e-07\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5303e-07\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4770e-07\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4242e-07\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3717e-07\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 3.3197e-07\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2699e-07\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2205e-07\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1715e-07\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1229e-07\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0751e-07\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0286e-07\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9828e-07\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9375e-07\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8929e-07\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8486e-07\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8042e-07\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7620e-07\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 2.7204e-07\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 994us/step - loss: 2.6792e-07\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6379e-07\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5977e-07\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5587e-07\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5199e-07\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4815e-07\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4442e-07\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.4063e-07\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3695e-07\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.3338e-07\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2988e-07\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2640e-07\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2295e-07\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1953e-07\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1617e-07\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 2.1291e-07\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0976e-07\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0655e-07\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0344e-07\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0035e-07\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9725e-07\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9421e-07\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9130e-07\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 997us/step - loss: 1.8842e-07\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8555e-07\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8274e-07\n",
            "[[2.000584 ]\n",
            " [0.9996392]]\n"
          ]
        }
      ],
      "source": [
        "# Define sequential model.\n",
        "ols = tf.keras.Sequential()\n",
        "\n",
        "# Add dense layer with linear activation.\n",
        "ols.add(tf.keras.layers.Dense(1, input_shape = (2,),\n",
        "    use_bias = False , activation = 'linear'))\n",
        "\n",
        "# Set optimizer and loss.\n",
        "ols.compile(optimizer = 'SGD', loss = 'mse')\n",
        "\n",
        "# Train model.\n",
        "ols.fit(X, Y, epochs = 500)\n",
        "\n",
        "# Print parameter estimates.\n",
        "print(ols.weights[0].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvq4U6R6GOQI"
      },
      "source": [
        "## **Listing 1-8.** Solve an OLS model with tf.estimator()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRtVQHiY9ay4",
        "outputId": "40cab9f6-9088-4748-9214-7891cbb99b73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Temp\\ipykernel_22656\\695527384.py:3: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Temp\\ipykernel_22656\\695527384.py:8: LinearRegressorV2.__init__ (from tensorflow_estimator.python.estimator.canned.linear) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py:1344: RegressionHead.__init__ (from tensorflow_estimator.python.estimator.head.regression_head) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py:1362: Estimator.__init__ (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1844: RunConfig.__init__ (from tensorflow_estimator.python.estimator.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\SE137D~1.520\\AppData\\Local\\Temp\\tmpt_jovlmx\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\SE137D~1.520\\\\AppData\\\\Local\\\\Temp\\\\tmpt_jovlmx', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:385: StopAtStepHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\optimizers\\legacy\\ftrl.py:173: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow_estimator\\python\\estimator\\model_fn.py:250: EstimatorSpec.__new__ (from tensorflow_estimator.python.estimator.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1416: NanTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1419: LoggingTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py:232: SecondOrStepTimer.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1456: CheckpointSaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\training\\monitored_session.py:579: StepCounterHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\training\\monitored_session.py:586: SummarySaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\SE137D~1.520\\AppData\\Local\\Temp\\tmpt_jovlmx\\model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1455: SessionRunArgs.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1454: SessionRunContext.__init__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1474: SessionRunValues.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "INFO:tensorflow:loss = 10.0, step = 0\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 100...\n",
            "INFO:tensorflow:Saving checkpoints for 100 into C:\\Users\\SE137D~1.520\\AppData\\Local\\Temp\\tmpt_jovlmx\\model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 100...\n",
            "INFO:tensorflow:Loss for final step: 3.1996308e-09.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressorV2 at 0x20bb1da0e80>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define feature columns.\n",
        "features = [\n",
        "tf.feature_column.numeric_column(\"constant\"),\n",
        "tf.feature_column.numeric_column(\"x1\")\n",
        "]\n",
        "\n",
        "# Define model.\n",
        "ols = tf.estimator.LinearRegressor(features)\n",
        "\n",
        "# Define function to feed data to model.\n",
        "def train_input_fn():\n",
        "\tfeatures = {\"constant\": [1, 1], \"x1\": [0, 2]}\n",
        "\ttarget = [2, 4]\n",
        "\treturn features, target\n",
        "\n",
        "# Train OLS model.\n",
        "ols.train(train_input_fn, steps = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckX9jaWpGW21"
      },
      "source": [
        "## **Listing 1-9.** Make predictions with an OLS model with tf.estimator()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE_5fjwh9cTW",
        "outputId": "a4a57361-f122-471f-c9df-c5094b8a33a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\regression_head.py:356: RegressionOutput.__init__ (from tensorflow.python.saved_model.model_utils.export_output) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From C:\\Users\\SE.5203\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\regression_head.py:364: PredictOutput.__init__ (from tensorflow.python.saved_model.model_utils.export_output) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from C:\\Users\\SE137D~1.520\\AppData\\Local\\Temp\\tmpt_jovlmx\\model.ckpt-100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[{'predictions': array([5.0000067], dtype=float32)}, {'predictions': array([7.000059], dtype=float32)}]\n"
          ]
        }
      ],
      "source": [
        "# Define feature columns.\n",
        "def test_input_fn():\n",
        "    features = {\"constant\": [1, 1], \"x1\": [3, 5]}\n",
        "    return features\n",
        "\n",
        "# Define prediction generator.\n",
        "predict_gen = ols.predict(input_fn=test_input_fn)\n",
        "\n",
        "# Generate predictions.\n",
        "predictions = [next(predict_gen) for j in range(2)]\n",
        "\n",
        "# Print predictions.\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovciiHIfGbIV"
      },
      "source": [
        "## **Listing 1-10.** List all available devices, select CPU, and then switch to GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "n2Peii5K9d1S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ],
      "source": [
        "# Print list of devices.\n",
        "devices = tf.config.list_physical_devices()\n",
        "print(devices)\n",
        "\n",
        "# Set device to CPU.\n",
        "tf.config.experimental.set_visible_devices(\n",
        "devices[0], 'CPU')\n",
        "\n",
        "# Change device to GPU.\n",
        "tf.config.experimental.set_visible_devices(\n",
        "devices[3], 'GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
