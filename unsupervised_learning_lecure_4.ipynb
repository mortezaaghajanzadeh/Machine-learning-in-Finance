{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mortezaaghajanzadeh/Machine-learning-in-Finance/blob/main/unsupervised_learning_lecure_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 4: Clustering and Dimensionality Reduction.**\n",
        "### Based on code from Chapter 8 in ``Machine Learning for Economics and Finance in TensorFlow 2'' (Hull, 2021)."
      ],
      "metadata": {
        "id": "uTxaRXhp98WS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries.\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cross_decomposition import PLSRegression"
      ],
      "metadata": {
        "id": "RH3GPpmU-KAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 8-1.** Define variables for PCA in TensorFlow."
      ],
      "metadata": {
        "id": "w5Lycwa7-SE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data path.\n",
        "data_path = 'https://www.dropbox.com/scl/fi/w092sf1lxbq7t489wtpec/gdp_growth.csv?rlkey=jrmun4nv96syk6bx5jc5tr2n2&dl=1'\n",
        "\n",
        "# Load data.\n",
        "C = pd.read_csv(data_path+'gdp_growth.csv', index_col = 'Date')\n",
        "\n",
        "# Convert data to constant object.\n",
        "C = tf.constant(np.array(C), tf.float32)\n",
        "\n",
        "# Set number of principal components.\n",
        "k = 5\n",
        "\n",
        "# Get shape of feature matrix.\n",
        "n, p = C.shape\n",
        "\n",
        "# Define variable for gamma matrix.\n",
        "G = tf.Variable(tf.random.normal((n, k)), tf.float32)\n",
        "\n",
        "# Define variable for beta matrix.\n",
        "B = tf.Variable(tf.random.normal((p, k)), tf.float32)"
      ],
      "metadata": {
        "id": "d9dAZ-Dx9QD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 8-2.** Perform PCA in TensorFlow."
      ],
      "metadata": {
        "id": "WQojvs3s-daM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define PCA loss.\n",
        "def pcaLoss(C, G, B):\n",
        "\tD = C - tf.matmul(G, tf.transpose(B))\n",
        "\tDT = tf.transpose(D)\n",
        "\tDDT = tf.matmul(D, DT)\n",
        "\treturn tf.linalg.trace(DDT)\n",
        "\n",
        "# Instantiate optimizer.\n",
        "opt = tf.optimizers.Adam()\n",
        "\n",
        "# Perform train model.\n",
        "for i in range(1000):\n",
        "\topt.minimize(lambda: pcaLoss(C, G, B),\n",
        "\tvar_list = [G, B])"
      ],
      "metadata": {
        "id": "j5E5gGui9UGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 8-3.** Import the PCA library from sklearn and prepare the data."
      ],
      "metadata": {
        "id": "gKYwm-I1-70A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data.\n",
        "C = pd.read_csv(data_path+'gdp_growth.csv',\n",
        "index_col = 'Date')\n",
        "\n",
        "# Transform feature matrix into numpy array.\n",
        "C = np.array(C)"
      ],
      "metadata": {
        "id": "eZmvxTpF9WZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 8-4.** Perform PCA with sklearn."
      ],
      "metadata": {
        "id": "1hOJKAxZGITB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of components.\n",
        "k = 25\n",
        "\n",
        "# Instantiate PCA model with k components.\n",
        "pca = PCA(n_components=k)\n",
        "\n",
        "# Fit model.\n",
        "pca.fit(C)\n",
        "\n",
        "# Return B matrix.\n",
        "B = pca.components_.T\n",
        "\n",
        "# Return G matrix.\n",
        "G = pca.transform(C)\n",
        "\n",
        "# Return variance shares.\n",
        "S = pca.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "9YN2Cwi19ZYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 8-5.** Prepare data for use in a principal components  regression."
      ],
      "metadata": {
        "id": "vvq4U6R6GOQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of components.\n",
        "k = 5\n",
        "\n",
        "# Instantiate PCA model with k components.\n",
        "pca = PCA(n_components=k)\n",
        "\n",
        "# Fit model and return principal components.\n",
        "pca.fit(C)\n",
        "G = tf.cast(pca.transform(C), tf.float32)\n",
        "\n",
        "# Initialize model parameters.\n",
        "beta = tf.Variable(tf.random.normal([k,1]), tf.float32)\n",
        "alpha = tf.Variable(tf.random.normal([1,1]), tf.float32)\n",
        "\n",
        "# Define prediction function.\n",
        "def PCR(G, beta, alpha):\n",
        "\tpredictions = alpha + tf.reshape(tf.matmul(G, beta), (236,))\n",
        "\treturn predictions\n",
        "\n",
        "# Define loss function.\n",
        "def mseLoss(Y, G, beta, alpha):\n",
        "\treturn tf.losses.mse(Y, PCR(G, beta, alpha))\n",
        "\n",
        "# Instantiate an optimizer and minimize loss.\n",
        "opt = tf.optimizers.Adam(0.1)\n",
        "for j in range(100):\n",
        "\topt.minimize(lambda: mseLoss(Y, G, beta,\n",
        "\talpha), var_list = [beta, alpha])"
      ],
      "metadata": {
        "id": "YRtVQHiY9ay4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 8-6.** Perform PLS."
      ],
      "metadata": {
        "id": "ckX9jaWpGW21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of components.\n",
        "k = 5\n",
        "\n",
        "# Instantiate PLS model with k components.\n",
        "pls = PLSRegression(n_components = k)\n",
        "\n",
        "# Train PLS model.\n",
        "pls.fit(C, Y)\n",
        "\n",
        "# Generate predictions.\n",
        "pls.predict(C)"
      ],
      "metadata": {
        "id": "hE_5fjwh9cTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 8-7.** Perform PLS."
      ],
      "metadata": {
        "id": "RAFRa4pJgcve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of components.\n",
        "k = 5\n",
        "\n",
        "# Instantiate PLS model with k components.\n",
        "pls = PLSRegression(n_components = k)\n",
        "\n",
        "# Train PLS model.\n",
        "pls.fit(C, Y)\n",
        "\n",
        "# Generate predictions.\n",
        "pls.predict(C)"
      ],
      "metadata": {
        "id": "YR7Ay7A5gfRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 8-8.** Train an autoencoder using the Keras API."
      ],
      "metadata": {
        "id": "iApx9mwbgklu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of countries.\n",
        "nCountries = 24\n",
        "\n",
        "# Set number of nodes in latent state.\n",
        "latentNodes = 5\n",
        "\n",
        "# Define input layer for encoder.\n",
        "encoderInput = tf.keras.layers.Input(shape = (nCountries))\n",
        "\n",
        "# Define latent state.\n",
        "latent = tf.keras.layers.Input(shape = (latentNodes))\n",
        "\n",
        "# Define dense output layer for encoder.\n",
        "encoded = tf.keras.layers.Dense(latentNodes, activation = 'tanh')(encoderInput)\n",
        "\n",
        "# Define dense output layer for decoder.\n",
        "decoded = tf.keras.layers.Dense(nCountries, activation = 'linear')(latent)\n",
        "\n",
        "# Define separate models for encoder and decoder.\n",
        "encoder = tf.keras.Model(encoderInput, encoded)\n",
        "decoder = tf.keras.Model(latent, decoded)\n",
        "\n",
        "# Define functional model for autoencoder.\n",
        "autoencoder = tf.keras.Model(encoderInput, decoder(encoded))\n",
        "\n",
        "# Compile model\n",
        "autoencoder.compile(loss = 'mse', optimizer='adam')\n",
        "\n",
        "# Train model\n",
        "autoencoder.fit(C, C, epochs = 200)"
      ],
      "metadata": {
        "id": "yMgNku-Zgo--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 8-9.** Autoencoder model architecture summary."
      ],
      "metadata": {
        "id": "Ea_mSHWhgqq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print summary of model architecture.\n",
        "print(autoencoder.summary())"
      ],
      "metadata": {
        "id": "thtIaWrOgxd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 8-10.** Generate latent state time series."
      ],
      "metadata": {
        "id": "2GIrEebzgzaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate latent state time series.\n",
        "latentState = encoder.predict(C)\n",
        "\n",
        "# Print shape of latent state series.\n",
        "print(latentState.shape)"
      ],
      "metadata": {
        "id": "lQCBdx6ng3id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 8-11.** Perform dimensionality reduction in a regression setting with an autoencoder latent state."
      ],
      "metadata": {
        "id": "yDM34wVeg4HM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model parameters.\n",
        "beta = tf.Variable(tf.random.normal([latentNodes,1]))\n",
        "alpha = tf.Variable(tf.random.normal([1,1]))\n",
        "\n",
        "# Define prediction function.\n",
        "def LSR(latentState, beta, alpha):\n",
        "\tpredictions = alpha + tf.reshape(\n",
        "tf.matmul(latentState, beta), (236,))\n",
        "\treturn predictions\n",
        "\n",
        "# Define loss function.\n",
        "def mseLoss(Y, latentState, beta, alpha):\n",
        "\treturn tf.losses.mse(Y, LSR(latentState,\n",
        "beta, alpha))\n",
        "\n",
        "# Instantiate an optimizer and minimize loss.\n",
        "opt = tf.optimizers.Adam(0.1)\n",
        "for j in range(100):\n",
        "\topt.minimize(lambda: mseLoss(Y,\n",
        "latentState, beta,\n",
        "alpha), var_list = [beta, alpha])"
      ],
      "metadata": {
        "id": "L9-xsXDVg-st"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}