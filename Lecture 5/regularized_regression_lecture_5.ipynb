{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mortezaaghajanzadeh/Machine-learning-in-Finance/blob/main/Lecture%205/regularized_regression_lecture_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 5: Regularized Regression.**\n",
        "### Based on code from Chapter 3 in ``Machine Learning for Economics and Finance in TensorFlow 2'' (Hull, 2021)."
      ],
      "metadata": {
        "id": "uTxaRXhp98WS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries.\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "RH3GPpmU-KAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 3-1.** Implement OLS in TensorFlow 2."
      ],
      "metadata": {
        "id": "w5Lycwa7-SE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data as constants.\n",
        "X = tf.constant([[1, 0], [1, 2]], tf.float32)\n",
        "Y = tf.constant([[2], [4]], tf.float32)\n",
        "\n",
        "# Compute vector of parameters.\n",
        "XT = tf.transpose(X)\n",
        "XTX = tf.matmul(XT,X)\n",
        "beta = tf.matmul(tf.matmul(tf.linalg.inv(XTX),XT),Y)"
      ],
      "metadata": {
        "id": "d9dAZ-Dx9QD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 3-2.** Generate input data for a linear regression."
      ],
      "metadata": {
        "id": "WQojvs3s-daM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of observations and samples\n",
        "S = 100\n",
        "N = 10000\n",
        "\n",
        "# Set true values of parameters.\n",
        "alpha = tf.constant([1.], tf.float32)\n",
        "beta = tf.constant([3.], tf.float32)\n",
        "\n",
        "# Draw independent variable and error.\n",
        "X = tf.random.normal([N, S])\n",
        "epsilon = tf.random.normal([N, S], stddev=0.25)\n",
        "\n",
        "# Compute dependent variable.\n",
        "Y = alpha + beta*X + epsilon"
      ],
      "metadata": {
        "id": "j5E5gGui9UGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 3-3.** Initialize variables and define the loss."
      ],
      "metadata": {
        "id": "gKYwm-I1-70A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw initial values randomly.\n",
        "alphaHat0 = tf.random.normal([1], stddev=5.0)\n",
        "betaHat0 = tf.random.normal([1], stddev=5.0)\n",
        "\n",
        "# Define variables.\n",
        "alphaHat = tf.Variable(alphaHat0, tf.float32)\n",
        "betaHat = tf.Variable(betaHat0, tf.float32)\n",
        "\n",
        "# Define function to compute MAE loss.\n",
        "def maeLoss(alphaHat, betaHat, xSample, ySample):\n",
        "\tprediction = alphaHat + betaHat*xSample\n",
        "\terror = ySample â€“ prediction\n",
        "\tabsError = tf.abs(error)\n",
        "\treturn tf.reduce_mean(absError)"
      ],
      "metadata": {
        "id": "eZmvxTpF9WZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 3-4.** Define an optimizer and minimize the loss function."
      ],
      "metadata": {
        "id": "1hOJKAxZGITB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer.\n",
        "opt = tf.optimizers.SGD()\n",
        "\n",
        "# Define empty lists to hold parameter values.\n",
        "alphaHist, betaHist = [], []\n",
        "\n",
        "# Perform minimization and retain parameter updates.\n",
        "for j in range(1000):\n",
        "\n",
        "# Perform minimization step.\n",
        "\topt.minimize(lambda: maeLoss(alphaHat, betaHat,\n",
        "\tX[:,0], Y[:,0]), var_list = [alphaHat,\n",
        "betaHat])\n",
        "\n",
        "# Update list of parameters.\n",
        "\talphaHist.append(alphaHat.numpy()[0])\n",
        "\tbetaHist.append(betaHat.numpy()[0])"
      ],
      "metadata": {
        "id": "9YN2Cwi19ZYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 3-5.** Plot the parameter training histories."
      ],
      "metadata": {
        "id": "vvq4U6R6GOQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define DataFrame of parameter histories.\n",
        "params = pd.DataFrame(np.hstack([alphaHist,\n",
        "betaHist]), columns = ['alphaHat', 'betaHat'])\n",
        "\n",
        "# Generate plot.\n",
        "params.plot(figsize=(10,7))\n",
        "\n",
        "# Set x axis label.\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Set y axis label.\n",
        "plt.ylabel('Parameter Value')"
      ],
      "metadata": {
        "id": "YRtVQHiY9ay4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 3-6.** Generate data for partially linear regression experiment."
      ],
      "metadata": {
        "id": "ckX9jaWpGW21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of observations and samples\n",
        "S = 100\n",
        "N = 10000\n",
        "\n",
        "# Set true values of parameters.\n",
        "alpha = tf.constant([1.], tf.float32)\n",
        "beta = tf.constant([3.], tf.float32)\n",
        "theta = tf.constant([0.05], tf.float32)\n",
        "\n",
        "# Draw independent variable and error.\n",
        "X = tf.random.normal([N, S])\n",
        "Z = tf.random.normal([N, S])\n",
        "epsilon = tf.random.normal([N, S], stddev=0.25)\n",
        "\n",
        "# Compute dependent variable.\n",
        "Y = alpha + beta*X + tf.exp(theta*Z) + epsilon"
      ],
      "metadata": {
        "id": "hE_5fjwh9cTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 3-7.** Initialize variables and compute the loss."
      ],
      "metadata": {
        "id": "RAFRa4pJgcve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw initial values randomly.\n",
        "alphaHat0 = tf.random.normal([1], stddev=5.0)\n",
        "betaHat0 = tf.random.normal([1], stddev=5.0)\n",
        "thetaHat0 = tf.random.normal([1], mean = 0.05,\n",
        "            stddev=0.10)\n",
        "\n",
        "# Define variables.\n",
        "alphaHat = tf.Variable(alphaHat0, tf.float32)\n",
        "betaHat = tf.Variable(betaHat0, tf.float32)\n",
        "thetaHat = tf.Variable(thetaHat0, tf.float32)\n",
        "\n",
        "# Compute prediction.\n",
        "def plm(alphaHat, betaHat, thetaHat, xS, zS):\n",
        "\tprediction = alphaHat + betaHat*xS + \\\n",
        "\t\t\ttf.exp(thetaHat*zS)\n",
        "\treturn prediction"
      ],
      "metadata": {
        "id": "YR7Ay7A5gfRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 3-8.** Define a loss function for a partially linear regression."
      ],
      "metadata": {
        "id": "iApx9mwbgklu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to compute MAE loss.\n",
        "def maeLoss(alphaHat, betaHat, thetaHat, xS, zS, yS):\n",
        "\tyHat = plm(alphaHat, betaHat, thetaHat, xS, zS)\n",
        "\treturn tf.losses.mae(yS, yHat)"
      ],
      "metadata": {
        "id": "yMgNku-Zgo--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 3-9.** Train a partially linear regression model."
      ],
      "metadata": {
        "id": "Ea_mSHWhgqq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate optimizer.\n",
        "opt = tf.optimizers.SGD()\n",
        "\n",
        "# Perform optimization.\n",
        "for i in range(1000):\n",
        "\topt.minimize(lambda: maeLoss(alphaHat, betaHat,\n",
        "\tthetaHat, X[:,0], Z[:,0], Y[:,0]),\n",
        "\tvar_list = [alphaHat, betaHat, thetaHat])"
      ],
      "metadata": {
        "id": "thtIaWrOgxd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 3-10.** Prepare the data for a TAR model of the USD-GBP exchange rate."
      ],
      "metadata": {
        "id": "2GIrEebzgzaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data path.\n",
        "data_path = 'https://www.dropbox.com/scl/fi/19tbysfgfl9skjni7sa70/exchange_rate.csv?rlkey=szefj9qseypfce9077khlhe53&dl=1'\n",
        "\n",
        "# Load data.\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Convert log exchange rate to numpy array.\n",
        "e = np.array(data['log_USD_GBP'])\n",
        "\n",
        "# Identify exchange decreases greater than 2%.\n",
        "de = tf.cast(np.diff(e[:-1]) < -0.02, tf.float32)\n",
        "\n",
        "# Define the lagged exchange rate as a constant.\n",
        "le = tf.constant(e[1:-1], tf.float32)\n",
        "\n",
        "# Define the exchange rate as a constant.\n",
        "e = tf.constant(e[2:], tf.float32)"
      ],
      "metadata": {
        "id": "lQCBdx6ng3id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 3-11.** Define parameters for a TAR model of the USD-GBP exchange rate."
      ],
      "metadata": {
        "id": "yDM34wVeg4HM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variables.\n",
        "rho0Hat = tf.Variable(0.80, tf.float32)\n",
        "rho1Hat = tf.Variable(0.80, tf.float32)"
      ],
      "metadata": {
        "id": "L9-xsXDVg-st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 3-12.** Define parameters for a TAR model of the USD-GBP exchange rate."
      ],
      "metadata": {
        "id": "jUl34j9QGlrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model.\n",
        "def tar(rho0Hat, rho1Hat, le, de):\n",
        "\t# Compute regime-specific prediction.\n",
        "\tregime0 = rho0Hat*le\n",
        "\tregime1 = rho1Hat*le\n",
        "\t# Compute prediction for regime.\n",
        "\tprediction = regime0*de + regime1*(1-de)\n",
        "\treturn prediction\n",
        "\n",
        "# Define loss.\n",
        "def maeLoss(rho0Hat, rho1Hat, e, le, de):\n",
        "\tehat = tar(rho0Hat, rho1Hat, le, de)\n",
        "\treturn tf.losses.mae(e, ehat)"
      ],
      "metadata": {
        "id": "UnDdrdqFGnE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 3-13.** Train TAR model of the USD-GBP exchange rate."
      ],
      "metadata": {
        "id": "DOV3gVxJGof1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer.\n",
        "opt = tf.optimizers.SGD()\n",
        "\n",
        "# Perform minimization.\n",
        "for i in range(20000):\n",
        "\topt.minimize(lambda: maeLoss(\n",
        "\trho0Hat, rho1Hat, e, le, de),\n",
        "\tvar_list = [rho0Hat, rho1Hat]\n",
        "\t)"
      ],
      "metadata": {
        "id": "sZ4EBWyLGuMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Listing 3-14.** Instantiate optimizers."
      ],
      "metadata": {
        "id": "101U0HSdGxIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate optimizers.\n",
        "sgd = tf.optimizers.SGD(learning_rate = 0.001,\n",
        "momentum = 0.5)\n",
        "rms = tf.optimizers.RMSprop(learning_rate = 0.001,\n",
        "\trho = 0.8, momentum = 0.9)\n",
        "agrad = tf.optimizers.Adagrad(learning_rate = 0.001,\n",
        "\tinitial_accumulator_value = 0.1)\n",
        "adelt = tf.optimizers.Adadelta(learning_rate = 0.001,\n",
        "\trho = 0.95)\n",
        "adam = tf.optimizers.Adam(learning_rate = 0.001,\n",
        "\tbeta_1 = 0.9, beta_2 = 0.999)"
      ],
      "metadata": {
        "id": "Lks3nnX-G0M5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}